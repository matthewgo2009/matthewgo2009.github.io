---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}




<!-- 开始复制 -->

<h2>Preprints & Working Papers</h2>

<p>
  <strong>On the Convergence and Stability of Distributed Sub-model Training</strong><br>
  <strong>Yuyang Deng</strong>, Fuli Qiao, Mehrdad Mahdavi.<br>
  <em>arXiv preprint arXiv:2511.06132</em>, 2025.<br>
  <a href="https://arxiv.org/abs/2511.06132" target="_blank">[arXiv]</a>
</p>

<p>
  <strong>Neyman-Pearson Classification under Both Null and Alternative Distributions Shift</strong><br>
  Mohammadreza Mousavi Kalan, <strong>Yuyang Deng</strong>, Eitan J. Neugut, Samory Kpotufe.<br>
  <em>arXiv preprint arXiv:2511.06641</em>, 2025.<br>
  <a href="https://arxiv.org/abs/2511.06641" target="_blank">[arXiv]</a>
</p>

<hr>

<h2>Conference Proceedings</h2>

<h3>2025</h3>

<p>
  <strong>Mixed-Sample SGD: an End-to-end Analysis of Supervised Transfer Learning</strong><br>
  <strong>Yuyang Deng</strong>, Samory Kpotufe.<br>
  In <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2025.<br>
  <a href="#">[PDF]</a> <!-- 记得替换这里的链接 -->
</p>

<p>
  <strong>Stochastic Compositional Minimax Optimization with Provable Convergence Guarantees</strong><br>
  <strong>Yuyang Deng</strong>, Fuli Qiao, Mehrdad Mahdavi.<br>
  In <em>International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2025.<br>
  <a href="#">[PDF]</a>
</p>

<h3>2024</h3>

<p>
  <strong>Collaborative Learning with Different Labeling Functions</strong><br>
  <strong>Yuyang Deng</strong>, Mingda Qiao.<br>
  In <em>International Conference on Machine Learning (ICML)</em>, 2024.<br>
  <a href="#">[PDF]</a> <a href="#">[Code]</a>
</p>

<p>
  <strong>On the Generalization Ability of Unsupervised Pretraining</strong><br>
  <strong>Yuyang Deng</strong>, Junyuan Hong, Jiayu Zhou, Mehrdad Mahdavi.<br>
  In <em>International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2024.<br>
  <a href="#">[PDF]</a>
</p>

<h3>2023</h3>

<p>
  <strong>Distributed Personalized Empirical Risk Minimization</strong><br>
  <strong>Yuyang Deng</strong>, Mohammad Mahdi Kamani, Pouria Mahdavinia, Mehrdad Mahdavi.<br>
  In <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023.<br>
  <a href="#">[PDF]</a>
</p>

<p>
  <strong>Mixture Weight Estimation and Model Prediction in Multi-source Multi-target Domain Adaptation</strong><br>
  <strong>Yuyang Deng</strong>, Ilja Kuzborskij, Mehrdad Mahdavi.<br>
  In <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023.<br>
  <a href="#">[PDF]</a>
</p>

<p>
  <strong>Understanding Deep Gradient Leakage via Inversion Influence Functions</strong><br>
  Haobo Zhang, Junyuan Hong, <strong>Yuyang Deng</strong>, Mehrdad Mahdavi, Jiayu Zhou.<br>
  In <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023.<br>
  <a href="#">[PDF]</a>
</p>

<h3>2022 & Prior</h3>

<p>
  <strong>Tight Analysis of Extra-gradient and Optimistic Gradient Methods For Nonconvex Mini-max Problems</strong><br>
  Pouria Mahdavinia, <strong>Yuyang Deng</strong>, Haochuan Li, Mehrdad Mahdavi.<br>
  In <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022.<br>
  <a href="#">[PDF]</a>
</p>

<p>
  <strong>Local SGD Optimizes Overparameterized Neural Networks in Polynomial Time</strong><br>
  <strong>Yuyang Deng</strong>, Mohammad Mahdi Kamani, Mehrdad Mahdavi.<br>
  In <em>International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2021.<br>
  <a href="#">[PDF]</a>
</p>

<p>
  <strong>Distributionally Robust Federated Averaging</strong><br>
  <strong>Yuyang Deng</strong>, Mohammad Mahdi Kamani, Mehrdad Mahdavi.<br>
  In <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2020.<br>
  <a href="#">[PDF]</a>
</p>

<p>
  <strong>Local Stochastic Gradient Descent Ascent: Convergence Analysis and Communication Efficiency</strong><br>
  <strong>Yuyang Deng</strong>, Mehrdad Mahdavi.<br>
  In <em>International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2020.<br>
  <a href="#">[PDF]</a>
</p>

<p>
  <strong>Adaptive Personalized Federated Learning</strong><br>
  <strong>Yuyang Deng</strong>, Mohammad Mahdi Kamani, Mehrdad Mahdavi.<br>
  <em>arXiv preprint arXiv:2003.13461</em>, 2020.<br>
  <a href="https://arxiv.org/abs/2003.13461" target="_blank">[arXiv]</a>
</p>

<!-- 结束复制 -->

